# Gensim学习笔记整理

Gensim是一个用来提取文本特征向量和计算文本相似度计算的python库，经过处理之后所有的文本都会变成特定长度的向量，每个向量中的每一个值都是小数，以便用于后续的模型训练。

# 精简版的Gensim向量提取及相似度对比

## 第一步，读取文本

```
f=open('questions.txt')
# 一口气读完文件
documents=f.readlines()
```

## 第二步，令牌化处理文本

```
stoplist = set('please for a of the and to in are can about other do were I like you your'.split())
```
停词，我们在处理文本时会忽略的词，在本次AI面试系统中大多为疑问词，介词和代词，因为这些词在文本中没有代表意义。
```
texts = [[word for word in document.lower().split() if word not in stoplist]
          for document in documents]
```
文本令牌化，将句子分割为一个一个不出现在停词列表里的单词的列表。
```
from collections import defaultdict
frequency = defaultdict(int)
for text in texts:
    for token in text:
        frequency[token] += 1
texts = [[token for token in text if frequency[token] > 1]
         for text in texts]
```
统计各个词语出现的频率，
```
from gensim import corpora
dictionary = corpora.Dictionary(texts)
dictionary.save('deerwester.dict') 
corpus = [dictionary.doc2bow(text) for text in texts]
corpora.MmCorpus.serialize('deerwester.mm', corpus) 
```
从gensim中导入corpora对象，调用Dictionary方法，从令牌化的文本中生成字典，为每个单词赋予唯一的ID标识，返回一个字典对象dictionary。
调用dictionary的doc2bow方法，可以将原本令牌化的文本转换成(id:count)的形式,也就是说每个句子中每个单词的id和它对应的出现次数。
corpus只会保存每个句子中单词的id和这个单词出现的次数
```
for i in range(10):
    print(list(corpus[10]))

[(1, 1), (2, 1), (3, 1), (11, 1), (20, 1)]
[(1, 1), (2, 1), (3, 1), (11, 1), (20, 1)]
[(1, 1), (2, 1), (3, 1), (11, 1), (20, 1)]
[(1, 1), (2, 1), (3, 1), (11, 1), (20, 1)]
[(1, 1), (2, 1), (3, 1), (11, 1), (20, 1)]
[(1, 1), (2, 1), (3, 1), (11, 1), (20, 1)]
[(1, 1), (2, 1), (3, 1), (11, 1), (20, 1)]
[(1, 1), (2, 1), (3, 1), (11, 1), (20, 1)]
[(1, 1), (2, 1), (3, 1), (11, 1), (20, 1)]
[(1, 1), (2, 1), (3, 1), (11, 1), (20, 1)]
```
可以用list(corpus)的方法查看corpus中存储的内容
可以用dic=dictionary.token2id的方法将将dictionary转化成标准的python字典形式，即单词和它对应的在字典中的id。
```
dic=dictionary.token2id
for i in dic:
    print(i,":",dic[i])

introduce : 0
yourself : 1
me : 2
tell : 3
company : 4
good : 5
manager : 6
name : 7
what : 8
describe : 9
style : 10
work : 11
hire : 12
should : 13
(只截取了一部分)
```
将产生的字典个corpus对象序列化保存成二进制文件
```
dictionary.save('deerwester.dict')
corpora.MmCorpus.serialize('deerwester.mm', corpus) 
```

## 第三步，将令牌化的文本转化成可用于训练的向量集合

```
dictionary = corpora.Dictionary.load('deerwester2.dict')
corpus = corpora.MmCorpus('deerwester2.mm')
```
导入之前保存的字典和corpus对象
```
from gensim import corpora, models, similarities
tfidf = models.TfidfModel(corpus)
```
tfidf是一个简单的训练模型，它会遍历整个corpus并计算特征频率，它可以快速的训练出一个转换模型，用来将corpus转化成向量的形式
```
lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=50) # initialize an LSI transformation
corpus_lsi = lsi[corpus_tfidf]

vectors=[[vector[1] for vector in doc ] for doc in corpus_lsi]
```
训练LSI模型，vectorc就是最后的结果
```
for i in range(10):
    print(vectors[i])

[0.06212305292140314, -0.1087255793889067, 0.04825403262162472, -0.12120662756300662, -0.07039337480815412, 0.28181718447037485, -0.0868483526077676, -0.04901952040450105, 0.10435504436315926, 0.22517190194274844]
[0.2613718805633888, -0.6685002205014208, 0.06422869675264198, -0.14359848830122848, -0.05501775729470476, 0.5451089244547329, -0.17235309849845282, 0.038674499499204595, 0.0697319207813071, 0.18756575771254136]
[0.1240703714448719, 0.00043726241571766244, -0.03996679590362908, -0.03132454540213051, 0.006480936120518672, -0.0028115114176879424, -0.026037411879261455, 0.11021091651093395, 0.02582985699155635, -0.16606636842313685]
[0.06212305292140314, -0.1087255793889067, 0.04825403262162472, -0.12120662756300662, -0.07039337480815412, 0.28181718447037485, -0.0868483526077676, -0.04901952040450105, 0.10435504436315926, 0.22517190194274844]
[0.1079596686959916, 0.037644966800999845, 0.0920315586765906, -0.07207983033718228, -0.04496693710228222, 0.06954294027700741, 0.10486346926846601, -0.24229640435322272, -0.323501938358843, -0.08092406555932852]
[0.15259905144288366, 0.044989824048627586, 0.17773739959727852, 0.1898403740284207, -0.02235049081437022, 0.04011058700200465, 0.2828550575145663, 0.05880054636226384, 0.07823485637207023, 0.26214495993229675]
[0.2613718805633888, -0.6685002205014208, 0.06422869675264198, -0.14359848830122848, -0.05501775729470476, 0.5451089244547329, -0.17235309849845282, 0.038674499499204595, 0.0697319207813071, 0.18756575771254136]
[0.2613718805633888, -0.6685002205014208, 0.06422869675264198, -0.14359848830122848, -0.05501775729470476, 0.5451089244547329, -0.17235309849845282, 0.038674499499204595, 0.0697319207813071, 0.18756575771254136]
[0.0350244358203973, -0.061825114179401154, 0.027535196102211917, -0.07497015768825707, -0.040718800252203806, 0.15834409733433136, -0.05255495883633592, -0.027159628475034607, 0.05791528704703099, 0.12027892440571589]
[0.2697876165371809, -0.37017302624844, -0.14935410248791978, -0.038901892139134586, 0.007324698387449107, 0.2705654696124312, -0.10510420601728836, 0.0028935109064713513, 0.043302997787215025, -0.14534761368167132]
```

## 相似度对比

```
import sys

anId=sys.argv[1]
doc=sys.argv[2]
```

获得两个参数，anId是问题在问题集中的id,doc是面试者的回答。

```
vec_bow = dictionary.doc2bow(doc.lower().split())
vec_lsi = lsi[vec_bow]
```

将回答用之前生成的字典令牌化，并将它转化到Lsi的模型中，

```
index = similarities.MatrixSimilarity(lsi[corpus])

sims = index[vec_lsi]

sims = sorted(enumerate(sims), key=lambda item: -item[1])
re=0
for sim in sims:
    if sim[0]==int(anId):
        re=sim[1]
print(re)
```

生成句子和其他句子的相似度，根据Id找出对应的相似度。


# Gensim中导入及衍生出的对象及方法整理

## corpora

gensim中带入的对象

## corpora.Dictionary(texts)

接受一个二维列表作为参数，将单词转化为字典，即（word:id）的形式，但是该方法产生的是一个gensim对象，无法直接读取。

## dictionary.doc2bow(text)

dictionary是上一个方法产生的gensim对象，该方法接受一个列表作为参数，将该列表中的每个单词转换为该单词在字典中的id和出现的次数的元祖的形式，并形成新的列表返回

## dictionary.token2id

将dictionary对象转化成python字典的形式，返回一个python字典,key是单词，对应的value是该单词对应的id

## dictionary.save('deerwester.dict') 

将字典保存在本地二进制文件

## dictionary.load('deerwester.dict')

读取以二进制形式保存的字典文件，返回一个gensim对象

## corpora.MmCorpus.serialize('deerwester.mm', corpus)

将已经令牌化的语料库序列化保存到硬盘上

## corpora.MmCorpus('deerwester.mm')

读取语料库

## models.TfidfModel(corpus)

调用tfid语义模型，将语料库转化成向量的形式

## models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=10)

Lsi语义模型，可已经语料库转化成向量，但是比tfid更加准确，接受三个参数，第一个是经过tfid处理过的向量集合，第二个是前面步骤生成的字典，第三个是生成的向量的长度

## tfidf[corpus] 和 lsi[corpus_tfidf]

返回生成的向量空间

## index=similarities.MatrixSimilarity(lsi[corpus])

生成每个句子彼此之间的相似度对比

## index[vec_lsi]

vec_lsi向量与其他向量的相似度


















