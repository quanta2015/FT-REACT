# 实验4

1 . 您刚刚被一家房地产投资公司聘用，希望您建立一个定价房屋的模型。已有的数据集包含房价数据，如卧室数量，平方英尺大小和房屋年龄。具体要求如下：

- 加载数据集 `housing-data.csv`
- 绘制每个要素的直方图
- 创建2个名为X和y的变量：X应为3列(sqft，bdrms，age)的矩阵，y应为1列(price)的向量
- 使用Keras创建具有适当数量的输入和输出的线性回归模型
- 将数据分成训练集和测试集，并以20％的测试尺寸进行测试
- 在训练集上训练模型并检查其在训练和测试集上的准确性
- 尝试通过以下方法改进模型：  
  1) 使用缩放技术来标准化输入要素  
  2) 使用不同的值来获得模型的学习率  
  3) 使用不同的优化器  
- 计算测试集上的R2评分



2 . 您的老板最近看到很多人离开公司，想了解为什么会这样。他收集了员工的历史数据，希望建立一个能够预测下一个员工将离开的模型。数据集中的字段包括： `员工满意度` `评价` `项目数量` `每月平均时数` `在职时间` `工伤事故` `晋升机会` `部门` `薪水` `是否离开`。这是一个分类问题。具体要求如下：

- 加载数据集 `HR_comma_sep.csv`
- 使用 `head`  `info` 和 `describe` 检查数据
- 建立一个基准：如果你预测每个人都留下来你的准确度得分是多少？
- 检查是否需要缩放特征，可以绘制要素的直方图，以确定哪种重新缩放方法更合适
- 将分类特征转换为二进制虚拟列。然后用`pd.concat`组合
- 以20％的比例进行训练/测试分割
- 建立模型进行学习和优化
- 检查混淆矩阵，精度和召回
- 如果对所有数据使用5折交叉验证，请检查是否仍然得到相同的结果



```python
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score

df = pd.read_csv('../data/housing-data.csv')
df.head()
#     sqft    bdrms   age price
# 0   2104    3   70  399900
# 1   1600    3   28  329900
# 2   2400    3   44  369000
# 3   1416    2   49  232000
# 4   3000    4   75  539900

df.columns
# Index([u'sqft', u'bdrms', u'age', u'price'], dtype='object')

# plot the histograms for each feature
plt.figure(figsize=(15, 5))
for i, feature in enumerate(df.columns):
    plt.subplot(1, 4, i+1)
    df[feature].plot(kind='hist', title=feature)
    plt.xlabel(feature)

# create 2 variables called X and y:
# X shall be a matrix with 3 columns (sqft,bdrms,age)
# and y shall be a vector with 1 column (price)
X = df[['sqft', 'bdrms', 'age']].values
y = df['price'].values

# split the data into train and test with a 20% test size
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# create a linear regression model in Keras
model = Sequential()
model.add(Dense(1, input_shape=(3,)))
model.compile(Adam(lr=0.8), 'mean_squared_error')
model.fit(X_train, y_train)

# check the R2score on training and test set (probably very bad)
y_train_pred = model.predict(X_train)
y_test_pred = model.predict(X_test)
print("The R2 score on the Train set is:\t{:0.3f}".format(r2_score(y_train, y_train_pred)))
print("The R2 score on the Test set is:\t{:0.3f}".format(r2_score(y_test, y_test_pred)))
# The R2 score on the Train set is:   -7.360
# The R2 score on the Test set is:    -7.687

# try to improve your model with these experiments:
# - normalize the input features with one of the rescaling techniques mentioned above
# - use a different value for the learning rate of your model
# - use a different optimizer
df['sqft1000'] = df['sqft']/1000.0
df['age10'] = df['age']/10.0
df['price100k'] = df['price']/1e5
X = df[['sqft1000', 'bdrms', 'age10']].values
y = df['price100k'].values
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

model = Sequential()
model.add(Dense(1, input_dim=3))
model.compile(Adam(lr=0.1), 'mean_squared_error')
model.fit(X_train, y_train, epochs=20)

# once you're satisfied with training, check the R2score on the test set
y_train_pred = model.predict(X_train)
y_test_pred = model.predict(X_test)
print("The R2 score on the Train set is:\t{:0.3f}".format(r2_score(y_train, y_train_pred)))
print("The R2 score on the Test set is:\t{:0.3f}".format(r2_score(y_test, y_test_pred)))
# The R2 score on the Train set is:   0.067
# The R2 score on the Test set is:    0.045

model.fit(X_train, y_train, epochs=40, verbose=0)
# once you're satisfied with training, check the R2score on the test set
y_train_pred = model.predict(X_train)
y_test_pred = model.predict(X_test)
print("The R2 score on the Train set is:\t{:0.3f}".format(r2_score(y_train, y_train_pred)))
print("The R2 score on the Test set is:\t{:0.3f}".format(r2_score(y_test, y_test_pred)))
# The R2 score on the Train set is:   0.660
# The R2 score on the Test set is:    0.531
```


```python

df = pd.read_csv('../data/HR_comma_sep.csv')
df.head()
df.info()
df.describe()
# Establish a benchmark: what would be your accuracy score if you predicted everyone stay?

df.left.value_counts() / len(df)

# Check if any feature needs rescaling.
# You may plot a histogram of the feature to decide which rescaling method is more appropriate.
df['average_montly_hours'].plot(kind='hist')

df['average_montly_hours_100'] = df['average_montly_hours']/100.0

df['average_montly_hours_100'].plot(kind='hist')

df['time_spend_company'].plot(kind='hist')

# convert the categorical features into binary dummy columns.
# You will then have to combine them with
# the numerical features using `pd.concat`.
df_dummies = pd.get_dummies(df[['sales', 'salary']])

df_dummies.head()

df.columns

X = pd.concat([df[['satisfaction_level', 'last_evaluation', 'number_project',
                   'time_spend_company', 'Work_accident',
                   'promotion_last_5years', 'average_montly_hours_100']],
               df_dummies], axis=1).values
y = df['left'].values

X.shape

# do the usual train/test split with a 20% test size
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# play around with learning rate and optimizer
model = Sequential()
model.add(Dense(1, input_dim=20, activation='sigmoid'))
model.compile(Adam(lr=0.5), 'binary_crossentropy', metrics=['accuracy'])
model.summary()
model.fit(X_train, y_train)
y_test_pred = model.predict_classes(X_test)

from sklearn.metrics import confusion_matrix, classification_report
def pretty_confusion_matrix(y_true, y_pred, labels=["False", "True"]):
    cm = confusion_matrix(y_true, y_pred)
    pred_labels = ['Predicted '+ l for l in labels]
    df = pd.DataFrame(cm, index=labels, columns=pred_labels)
    return df

# check the confusion matrix, precision and recall
pretty_confusion_matrix(y_test, y_test_pred, labels=['Stay', 'Leave'])
print(classification_report(y_test, y_test_pred))

from keras.wrappers.scikit_learn import KerasClassifier
# check if you still get the same results if you use a 5-Fold cross validation on all the data
def build_logistic_regression_model():
    model = Sequential()
    model.add(Dense(1, input_dim=20, activation='sigmoid'))
    model.compile(Adam(lr=0.5), 'binary_crossentropy', metrics=['accuracy'])
    return model

model = KerasClassifier(build_fn=build_logistic_regression_model,
                        epochs=10, verbose=0)

from sklearn.model_selection import KFold, cross_val_score
cv = KFold(5, shuffle=True)
scores = cross_val_score(model, X, y, cv=cv)
print("The cross validation accuracy is {:0.4f} ± {:0.4f}".format(scores.mean(), scores.std()))
```







