title: 神经网络
theme: light

<style>
.m-cnn { width: 600px; margin: 10px; }
.m-col2 { width: 360px; margin: 10px; }
</style>

[slide]
# 深度学习的类型
- 监督学习: 根据已知数据集做训练，对未知数据集合做分类；所有的监督学习基本上是“分类”的代名词，从有标签的训练数据中学习模型，然后给定某个新数据，利用模型预测新数据的标签。这里的标签，即使就是某个事物的分类。
- 非监督学习： 本质上是“聚类”的近义词。给定N个对象，将其分成K个子集，使得每个子集内的对象相似，不同子集之间的对象不相似。聚类指的是，将物理或抽象对象的集合分成由类似对象组成的多个类的过程。聚类的关键是如何度量对象间的相似性。聚类分析通常分四步走，即数据表示、聚类判据、聚类算法和聚类评估。聚类判据是确定聚类搜索的方向。
- 强化学习：在一系列的情景之下，选择最佳决策，它讲究通过多步恰当的决策，来逼近一个最优的目标，因此，它是一个多步决策的问题。



[slide]
# ANN - 人工神经网络
人工神经网络（Artificial Neural Network，ANN）简称神经网络(NN)。是基于生物学中神经网络的基本原理，在理解和抽象了人脑结构和外界刺激响应机制后，以网络拓扑知识为理论基础。模拟人脑的神经系统对复杂信息的处理机制的一种数学模型。

# 人工神经网络的结构
1. 神经元按照层来布局,一般由输入层、隐藏层和输出层构成;
2. 同一层的神经元没有连接。 
3. 第N层的每个神经元都第N-1层的所有神经元连接（这就是Full connected的含义），第N-1层神经元的输出就是第N层神经元的输入。 
4. 每个神经元的连接都具有一个权值。 
5. 隐藏层可以是多层。

<img src="../../img/cloud/deep/ann01.png"  class="m-cnn">

人工神经网络具有自学习和自适应的能力，能够通过预先提供的一批相互相应的输入输出数据，分析两者的内在关系和规律，终于通过这些规律形成一个复杂的非线性系统函数，这样的学习分析过程被称作 `训练` 。经网络由大量的节点之间相互联接构成，每一个节点代表一种特定的输出函数，称为激活函数 `activation function` ，每两个节点间的连接都代表一个对于通过该连接信号的加权值，称之为权重 `weight` 。因此，网络的输出则取决于网络的结构、网络的连接方式、权重和激活函数。
<img src="../../img/cloud/deep/ann02.png"  class="m-cnn">


# 学习分类
在实践中，我们会收集一些数据，并基于此创建预测、分类或进行其他处理，这个数据集则被称为训练集。事实上，根据训练期间的行为和训练集的性质，可以将学习分为3类：

- 无监督学习: 训练集仅包括输入, 网络识别相似的输入并把他们分类, 主要用于解决分类问题。
- 强化学习: 训练集包括输入，但是在训练期间也会给网络提供额外的信息。 内部机制是一旦网络计算出某个输入的输出，就提供信息以表明计算结果是正确的还是错误的，并且可能表明网络错误的性质。
- 监督学习: 训练集包括输入和期望的输出, 通过这种方式，网络可以检查它的计算结果和期望输出相不相同，并据此采取适当的行动。

> ann主要是通过监督学习来进行学习的

# 反向传播模型 
反向传播模型也称B-P模型，是一种用于前向多层的反向传播学习算法。之所以称它是一种学习方法，是因为用它能够对组成前向多层网络的各人工神经元之间的连接权值进行不断的改动，从而使该前向多层网络能够将输入它的信息变换成所期望的输出信息。之所以将其称作为反向学习算法，是因为在改动各人工神经元的连接权值时，所依据的是该网络的实际输出与其期望的输出之差，将这一差值反向一层一层的向回传播，来决定连接权值的改动。

<img src="../../img/cloud/deep/ann04.png"  class="m-cnn">
<img src="../../img/cloud/deep/ann05.png"  class="m-cnn">

# B-P算法的学习步骤

1. 选择一组训练例子，每一个例子由输入信息和期望的输出结果两部分组成。
2. 从训练例子集中取一例子。把输入信息输入到网络中。
3. 分别计算经神经元处理后的各层节点的输出。
4. 计算网络的实际输出和期望输出的误差。
5. 从输出层反向计算到第一个隐层。并依照某种能使误差向减小方向发展的原则，调整网络中各神经元的连接权值。
6. 对训练例子集中的每一个例子重复(3)-(5)的步骤，直到对整个训练例子集的误差达到要求时为止。

<img src="../../img/cloud/deep/ann06.png"  class="m-cnn">
<img src="../../img/cloud/deep/ann07.png"  class="m-cnn">


# 梯度下降 - gradient descent
整个训练的关键是给权重设置正确的值，从而在神经网络中得到期望的输出。这就意味着，我们要使误差向量尽可能小，即找到成本函数的全局最小值; 其解决办法是用微积分计算导数，然而成本函数是网络所有权重的函数，这是为什么要使用梯度下降。
<img src="../../img/cloud/deep/ann08.png"  class="m-cnn">
<img src="../../img/cloud/deep/ann09.png"  class="m-cnn">

有一个类比可以很好的描述该过程，想象你有一个小球位于如下图所示的山谷中，如果你让小球滚动，它将会从山谷的一边滚到另一边，最终到达谷底。本质上，可以如此看待小球的行为：小球从左到右优化它的位置，最终到达谷底，底部就是误差函数的最小值。每次计算导数时，都可以得到当前位置山谷边坡的斜率信息。
<img src="../../img/cloud/deep/ann10.png"  class="m-cnn">


# 学习率 - learning rate
学习率作为监督学习以及深度学习中重要的超参，其决定着目标函数能否收敛到局部最小值以及何时收敛到最小值。合适的学习率能够使目标函数在合适的时间内收敛到局部最小值。

由下图可以看出来，当学习率设置的过小时，收敛过程将变得十分缓慢。而当学习率设置的过大时，梯度可能会在最小值附近来回震荡，甚至可能无法收敛。
<img src="../../img/cloud/deep/ann17.png"  class="m-cnn">


# 局部最优
然而现实问题并不像上述描述这么简单，因为参数不仅仅是2维图像，网络节点的数量决定了函数是n维的模型，因此此时通常采用局部最优来解决问题，即只要计算出某个定义域范围内的谷底最优解即可。如下图，分别描述了3维函数和2维多态曲线的情况。
<img src="../../img/cloud/deep/ann11.png"  class="m-cnn">


# 激活函数
激活函数（Activation Function），就是在人工神经网络的神经元上运行的函数，负责将神经元的输入映射到输出端。

- 线性激活函数：最简单的linear function就是f(x) = x，不对输入进行修改就直接输出
- 非线性激活函数：这些函数用于对不可线性分离的数据进行分离，是最常用的激活函数。非线性方程控制从输入到输出的映射。常用的非线性激活函数的例子是Sigmoid，tanH，ReLU，LReLU，PReLU，Swish等。

<img src="../../img/cloud/deep/ann03.png"  class="m-cnn">


# 激活函数的性质

- 非线性： 当激活函数是线性的时候，一个两层的神经网络就可以逼近基本上所有的函数了。但是，如果激活函数是恒等激活函数的时候（即f(x)=xf(x)=x），就不满足这个性质了，而且如果MLP使用的是恒等激活函数，那么其实整个网络跟单层神经网络是等价的。
- 可微性： 当优化方法是基于梯度的时候，这个性质是必须的。
- 单调性： 当激活函数是单调的时候，单层网络能够保证是凸函数。
= f(x)≈xf(x)≈x： 当激活函数满足这个性质的时候，如果参数的初始化是random的很小的值，那么神经网络的训练将会很高效；如果不满足这个性质，那么就需要很用心的去设置初始值。
- 输出值的范围： 当激活函数输出值是 有限 的时候，基于梯度的优化方法会更加 稳定，因为特征的表示受有限权值的影响更显著；当激活函数的输出是 无限 的时候，模型的训练会更加高效，不过在这种情况小，一般需要更小的learning rate.

# Threshold Function

<img src="../../img/cloud/deep/ann13.png"  class="m-cnn">

# Sigmoid 
`Sigmoid` 能够把输入的连续实值压缩到0和1之间。 而且如果是非常大的负数，那么输出就是0；如果是非常大的正数，输出就是1。`Sigmoids` 的缺点如下：

- `Sigmoids saturate and kill gradients`: 当输入非常大或者非常小的时候`saturation`，神经元的梯度是接近于0的，从图中可以看出梯度的趋势。所以，你需要尤其注意参数的初始值来尽量避免`saturation`的情况。如果你的初始值很大的话，大部分神经元可能都会处在`saturation`的状态而把`gradient kill`掉，这会导致网络变的很难学习。
- `Sigmoid` 的 `output` 不是0均值: 这是不可取的，因为这会导致后一层的神经元将得到上一层输出的非0均值的信号作为输入。 
产生的一个结果就是：如果数据进入神经元的时候是正的(e.g. x>0x>0 elementwise in f=wTx+bf=wTx+b)，那么计算出的梯度也会始终都是正的。 

<img src="../../img/cloud/deep/ann14.png"  class="m-cnn">



# ReLU 
ReLU是最常用的激励函数，它解决了 `sigmoid` 和 `tanh` 中常见的梯度消失问题，同时也是计算梯度最快的激励函数。它并不挤压值至某一区间，它只是保留正值，并将所有负值转化为零。使用ReLU的积极方面是它的梯度要么是1（正值），要么是0（负值），再也没有梯度消失了，这一模式使网络更快收敛; 另一方面，这一表现导致所谓的“死亡神经元”问题，也就是输入持续为负的神经元激活值总是为零。

ReLU 的优点:

- 收敛速度快很多, 因为它是linear;
- 只需要一个阈值就可以得到激活值，而不用去算一大堆复杂的运算；

ReLU 的缺点: 就是训练的时候很脆弱，很容易就 `die` 了； 什么意思呢？举个例子：一个非常大的梯度流过一个 ReLU 神经元，更新过参数之后，这个神经元再也不会对任何数据有激活现象了。如果这个情况发生了，那么这个神经元的梯度就永远都会是0。实际操作中，如果你的 learning rate 很大，那么很有可能你网络中的40%的神经元都”dead”了。当然，如果你设置了一个合适的较小的learning rate, 这个问题发生的情况其实也不会太频繁。

<img src="../../img/cloud/deep/ann15.png"  class="m-cnn">

# Tanh 
`tanh` 跟 `sigmoid` 还是很像的，实际上，`tanh` 是`sigmoid`的变形。与 `sigmoid` 不同的是，`tanh` 是0均值的。因此，实际应用中，`tanh` 会比 `sigmoid` 更好。

<img src="../../img/cloud/deep/ann16.png"  class="m-cnn">


# 优化方法 
两张动图从直观上展现了算法的优化过程。第一张图为不同算法在损失平面等高线上随时间的变化情况，第二张图为不同算法在鞍点处的行为比较。

- SGD
- Momentum
- AdaGrad
- RMSProp
- Adam

<img src="../../img/cloud/deep/ann01.gif"  class="m-col2">
<img src="../../img/cloud/deep/ann02.gif"  class="m-col2">

# SGD
1 . BGD `Batch Gradient Descent` : 在每一轮的训练过程中，Batch Gradient Descent算法用整个训练集的数据计算cost fuction的梯度，并用该梯度对模型参数进行更新。

优点: cost fuction 若为凸函数，能够保证收敛到全局最优值；若为非凸函数，能够收敛到局部最优值
缺点: 
- 由于每轮迭代都需要在整个数据集上计算一次，所以批量梯度下降可能非常慢
- 训练数较多时，需要较大内存
- 批量梯度下降不允许在线更新模型，例如新增实例。

2 . SGD `Stochastic Gradient Descent`: 和批梯度下降算法相反，SGD 算法每读入一个数据，便立刻计算cost fuction的梯度来更新参数

优点:  
- 算法收敛速度快(在Batch Gradient Descent算法中, 每轮会计算很多相似样本的梯度, 这部分是冗余的)
- 可以在线更新
- 有几率跳出一个比较差的局部最优而收敛到一个更好的局部最优甚至是全局最优

缺点:  容易收敛到局部最优，并且容易被困在鞍点

3 . MGD `Mini-batch Gradient Descent`: MGD是在上述两个方法中取折衷, 每次从所有训练数据中取一个子集 `mini-batch` , 在每轮迭代中仅仅计算一个mini-batch的梯度，不仅计算效率高，而且收敛较为稳定。该方法是目前深度学训练中的主流方法


> 上述三个方法面临的主要挑战如下：
- 选择适当的学习率α较为困难。太小的学习率会导致收敛缓慢，而学习速度太块会造成较大波动，妨碍收敛。
- 目前可采用的方法是在训练过程中调整学习率大小，例如模拟退火算法：预先定义一个迭代次数m，每执行完m次训练便减小学习率，或者当cost function的值低于一个阈值时减小学习率。然而迭代次数和阈值必须事先定义，因此无法适应数据集的特点。
- 上述方法中, 每个参数的 learning rate 都是相同的，这种做法是不合理的：如果训练数据是稀疏的，并且不同特征的出现频率差异较大，那么比较合理的做法是对于出现频率低的特征设置较大的学习速率，对于出现频率较大的特征数据设置较小的学习速率。
- 近期的的研究表明，深层神经网络之所以比较难训练，并不是因为容易进入local minimum。相反，由于网络结构非常复杂，在绝大多数情况下即使是 local minimum 也可以得到非常好的结果。而之所以难训练是因为学习过程容易陷入到马鞍面中，即在坡面上，一部分点是上升的，一部分点是下降的。而这种情况比较容易出现在平坦区域，在这种区域中，所有方向的梯度值都几乎是 0。

# Momentum
Momentum
SGD方法的一个缺点是其更新方向完全依赖于当前batch计算出的梯度，因而十分不稳定。Momentum算法借用了物理中的动量概念，它模拟的是物体运动时的惯性，即更新的时候在一定程度上保留之前更新的方向，同时利用当前batch的梯度微调最终的更新方向。这样一来，可以在一定程度上增加稳定性，从而学习地更快，并且还有一定摆脱局部最优的能力。

​**一种形象的解释是：**我们把一个球推下山，球在下坡时积聚动量，在途中变得越来越快，γ可视为空气阻力，若球的方向发生变化，则动量会衰减。

# Nesterov Momentum
在小球向下滚动的过程中，我们希望小球能够提前知道在哪些地方坡面会上升，这样在遇到上升坡面之前，小球就开始减速。这方法就是Nesterov Momentum，其在凸优化中有较强的理论保证收敛。并且，在实践中Nesterov Momentum也比单纯的 Momentum 的效果好

其核心思想是：注意到 momentum 方法，如果只看 γ * v 项，那么当前的 θ经过 momentum 的作用会变成 θ-γ * v。因此可以把 θ-γ * v这个位置看做是当前优化的一个”展望”位置。所以，可以在 θ-γ * v求导, 而不是原始的θ。


# Adagrad
上述方法中，对于每一个参数θi的训练都使用了相同的学习率α。Adagrad算法能够在训练中自动的对learning rate进行调整，对于出现频率较低参数采用较大的α更新；相反，对于出现频率较高的参数采用较小的α更新。因此，Adagrad非常适合处理稀疏数据。


# RMSprop
RMSprop是Geoff Hinton提出的一种自适应学习率方法。Adagrad会累加之前所有的梯度平方，而RMSprop仅仅是计算对应的平均值，因此可缓解Adagrad算法学习率下降较快的问题。

# Adam
Adam(Adaptive Moment Estimation)是另一种自适应学习率的方法。它利用梯度的一阶矩估计和二阶矩估计动态调整每个参数的学习率。Adam的优点主要在于经过偏置校正后，每一次迭代学习率都有个确定范围，使得参数比较平稳。另外，在数据比较稀疏的时候，adaptive的方法能得到更好的效果，例如Adagrad，RMSprop, Adam 等。Adam 方法也会比RMSprop方法收敛的结果要好一些, 所以在实际应用中 ，Adam为最常用的方法，可以比较快地得到一个预估结果。


# 指数移动平均值 - EWMA 
EWMA(Exponentially Weighted Moving Average)指数加权移动平均，是一种常用的序列数据处理方式。

在t时刻，根据实际的观测值可以求取EWMA(t)：
```bash
# EWMA(t): t时刻的估计值；
# X(t): t时刻的测量值；
# n: 所观察的总的时间；
# a(0 < a <1): 表示对于历史测量值权重系数

EWMA(t) = aX(t) + (1-a)EWMA(t-1)，t = 1,2,.....,n；
```

之所以称之为指数加权，是因为加权系数a是以指数式递减的，即各指数随着时间而指数式递减。用n表示为`a = 2/(n+1)`。系数a越接近1表示对当前抽样值的权重越高，对过去测量值得权重越低，估计值(器)的时效性就越强，反之，越弱；另外，EWMA还有一定的吸收瞬间突发的能力，也即平稳性，显然随着a减小，参考过去测量值的程度更多一些，平稳性增强，反之则降低。主要用于降低图像噪声和平滑曲线的功能。

<img src="../../img/cloud/deep/ann18.png"  class="m-cnn">


# ANN范例 - 评估信用卡用户
问题描述：目前有银行客户的数据资料，包括姓名、信用评分、国别、性别、年龄、任期、余额、是否拥有信用卡、工资等信息，希望预测该用户是否会保留使用信用卡。

```python
import keras
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import Dense
from sklearn.metrics import confusion_matrix 
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.preprocessing import StandardScaler

# 导入数据
dataset = pd.read_csv('Churn_Modelling.csv')
X = dataset.iloc[:, 3:13].values
y = dataset.iloc[:, 13].values

# 标签编码 - 国别/性别
X[:, 1] = LabelEncoder().fit_transform(X[:, 1])
X[:, 2] = LabelEncoder().fit_transform(X[:, 2])
# 独热编码 - 国别
onehotencoder = OneHotEncoder(categorical_features = [1])
X = onehotencoder.fit_transform(X).toarray()
X = X[:, 1:]

# 分割训练集合和测试集合
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)

# 标准化编码
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

# 建立keras模型
classifier = Sequential()
classifier.add(Dense(kernel_initializer = 'uniform', activation = 'relu', input_dim = 11, units = 6))
classifier.add(Dense(kernel_initializer = 'uniform', activation = 'relu', units = 6))
classifier.add(Dense(kernel_initializer = 'uniform', activation = 'sigmoid', units = 1))
classifier.compile(optimizer = 'adam', loss ='binary_crossentropy', metrics = ['accuracy'] )
classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)

# 预测模型结果
y_pred = classifier.predict(X_test)
y_pred = (y_pred > 0.5)

# 计算准确度
cm = confusion_matrix(y_test,y_pred)

# 预测某客户是否会继续办理信用卡
new_pred = classifier.predict(sc.transform(np.array([[0.0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])))
```

[slide]
# CNN - 卷积神经网络
卷积神经网络（Convolutional Neural Network, CNN）是一种前馈神经网络，与普通神经网络非常相似，它们都由具有可学习的权重和偏置常量 `biases` 的神经元组成。每个神经元都接收一些输入，并做一些点积计算，输出是每个分类的分数。卷积神经网络默认输入是图像，可以让我们把特定的性质编码入网络结构，使是我们的前馈函数更加有效率，并减少了大量参数。


[slide]
# 卷积神经网络的用途
卷积神经网络CNN主要用来识别位移、缩放及其他形式扭曲不变性的二维图形。由于CNN的特征检测层通过训练数据进行学习，所以在使用CNN时，避免了显式的特征抽取，而隐式地从训练数据中进行学习；再者由于同一特征映射面上的神经元权值相同，所以网络可以并行学习，这也是卷积网络相对于神经元彼此相连网络的一大优势。卷积神经网络以其局部权值共享的特殊结构在语音识别和图像处理方面有着独特的优越性，其布局更接近于实际的生物神经网络，权值共享降低了网络的复杂性，特别是多维输入向量的图像可以直接输入网络这一特点避免了特征提取和分类过程中数据重建的复杂度。


# MNIST
黑白图像可以采用1和0表示黑白进行编码，而灰度图像可以用0-255表示灰度值进行编码。而MNIST是美国国家标准与技术研究所采集的手写的数字训练集，由250 个不同人手写的数字构成, 其中 50% 是高中学生, 50% 来自人口普查局的工作人员。每个手写数字都是通过28*28的灰度图像构成， 可以通过 784个数值构成的1维数组表示。

<img src="../../img/cloud/deep/cnn21.png"  class="m-cnn">

因此我们只要把MNIST数据转换为1维784向量的数组作为神经网络的输入数据，而输出用softmax函数输出10个节点即可。
<img src="../../img/cloud/deep/cnn22.png"  class="m-cnn">


# 图像编码方法
除了上述的编码方法外，其他还有下面几种编码方法，但是到底采用哪种编码方式来处理，取决于图像特征的类型和模型计算方法, 即领域知识。

- 傅立叶系数 fourier coefficients
- 小波 wavelets
- 定向梯度柱状图 histogram of oriented gradients
- 加速稳健特征 speeded up robust festures
- 局部二进制模式 local binary patterns
- 颜色直方图 color histograms

# 张量 Tensor
- 标量 Scalar: 3
- 向量 Vectors: `[0,1,0] 三维向量`  `[0.5, 1] 二维向量` `[4,5,0,3,1,6,2] 7维向量`
- 矩阵 Matrices: [[0,1,0], [5,0,2]] 2*3矩阵   MNIST 28*28矩阵
- 张量 Tensor: [[[0,1,0], [5,0,2]], [[1,2,4], [8,3,1]]] 

# 1维卷积
这里我们用一个简单的模型来演示卷积模型。有一个2元向量g[-1,1]和10元向量[0,0,0,0,0,1,1,1,1,1],首先让g[0]*f[0]+g[1]*f[1]计算出0，然后g向右移动1格计算g[0]*f[1]+g[1]*f[2],以此类推计算出9个结果形成新的向量，这个过程就是卷积。通过卷积可以方便的实现分类、特征判定等功能。

<img src="../../img/cloud/deep/cnn23.png"  class="m-cnn">
<img src="../../img/cloud/deep/cnn24.gif"  class="m-cnn">


[slide]
# 问题说明
下面我们通过一个识别叉和圈的范例来说明。  
<img src="../../img/cloud/deep/cnn02.png"  class="m-cnn">

[slide]
# 问题分析
但是实际的输入数据，可能存在位移、变形或者旋转。
<img src="../../img/cloud/deep/cnn03.png"  class="m-cnn">


[slide]
此时，如何判断变形后的图像和原始图像是同一类数据？
<img src="../../img/cloud/deep/cnn04.png"  class="m-cnn">


[slide]
# Step1. 卷积层 Convolutional layer
卷积神经网路中每层卷积层由若干卷积单元组成，每个卷积单元的参数都是通过反向传播算法优化得到的。卷积运算的目的是提取输入的不同特征，第一层卷积层可能只能提取一些低级的特征如边缘、线条和角等层级，更多层的网络能从低级特征中迭代提取更复杂的特征。


[slide]
而事实上，计算机看到的图像只是由数字组成。如果通过矩阵比较数值，两者明显是不相同的。
<img src="../../img/cloud/deep/cnn05.png"  class="m-cnn">


[slide]
但是如果将图像进行切割，如下图分成3个模块，再通过这3种模块比较图像。
<img src="../../img/cloud/deep/cnn06.png"  class="m-cnn">

<img src="../../img/cloud/deep/cnn07.png"  class="m-cnn">

[slide]
# 特征量计算过程

1. 分析图像特征量
2. 将特征量的每个像素相乘，并且加和
3. 最后除以特征量的像素总数


[slide]
<img src="../../img/cloud/deep/cnn08.png"  class="m-cnn">

[slide]
<img src="../../img/cloud/deep/cnn09.png"  class="m-cnn">

[slide]
<img src="../../img/cloud/deep/cnn10.png"  class="m-cnn">

[slide]
通过3个特征量，可以计算出3个不同的特征矩阵；这样一张图像就变成了一组过滤后的图像集合。
<img src="../../img/cloud/deep/cnn11.png"  class="m-cnn">

[slide]
# Step2. 池化

通常在卷积层之后会得到维度很大的特征，将特征切成几个区域，取其最大值或平均值，得到新的、维度较小的特征。池化算法过程:

1. 选择窗口大小，通常2或3
2. 选择步长，通常2
3. 让窗口在图像遍历
4. 在每个窗口选择最大值作为结果

[slide]
<img src="../../img/cloud/deep/cnn12.png"  class="m-cnn">

[slide]
<img src="../../img/cloud/deep/cnn13.png"  class="m-cnn">

[slide]
<img src="../../img/cloud/deep/cnn14.png"  class="m-cnn">

[slide] 
### 步长
<img src="../../img/cloud/deep/cnn26.png"  class="m-cnn">

[slide] 
### 填充
<img src="../../img/cloud/deep/cnn27.png"  class="m-cnn">

### 张量卷积
<img src="../../img/cloud/deep/cnn28.png"  class="m-cnn">


[slide]
# Step3. 线性整流层 Rectified Linear Units layer, ReLU layer 

这层神经的活性化函数（Activation function）使用线性整流（Rectified Linear Units, ReLU），通过稍微调整每个值来防止运算中断, 即把所有的负值转换成零。

[slide]
<img src="../../img/cloud/deep/cnn15.png"  class="m-cnn">

[slide]
<img src="../../img/cloud/deep/cnn16.png"  class="m-cnn">

[slide]
<img src="../../img/cloud/deep/cnn17.png"  class="m-cnn">

[slide]
卷积、池化和标准化可以反复迭代多次

<img src="../../img/cloud/deep/cnn18.png"  class="m-cnn">

[slide]
# Step4. 全连接层

把所有局部特征结合变成全局特征，用来计算最后每一类的得分。

[slide]
<img src="../../img/cloud/deep/cnn19.png"  class="m-cnn">

[slide]
<img src="../../img/cloud/deep/cnn20.png"  class="m-cnn">

[slide]
# 数据增强优化
通过增加训练数据的样本量，可以提高训练的准确度。一般可以通过下面方法，根据已有样本数据，自动产生新的数据：

- 旋转
- 缩放
- 镜像
- 变焦
- 颜色通道偏移

```
from keras.preprocessing.image import ImageDataGenerator
datagen = ImageDataGenerator (
    rotation_range= 40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)
datagen.fit(X_train)
```


# CNN 应用场景
CNN主要用于图像方面的应用，但是对于声音和文字也可以建模。

- 音乐： x轴为时间，y轴为频率
- 文字： x轴为出现在句子中的位置，y轴为在字典中的位置

<img src="../../img/cloud/deep/cnn25.png"  class="m-cnn">



# 手写体识别

```python
import keras 
import matplotlib.pyplot as plt
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten

epochs = 10
batch_size = 32
num_of_classes = 10
pixel_width = 28
pixel_height = 28
input_shape = (pixel_width, pixel_height, 1)

(features_train, labels_train),(features_test, labels_test) = mnist.load_data()

# 修改数据结构
features_train = features_train.reshape(features_train.shape[0], pixel_width, pixel_height, 1)
features_test = features_test.reshape(features_test.shape[0], pixel_width, pixel_height, 1)

# 将数据转换成浮点百分比
features_train = features_train.astype('float32')/255
features_test = features_test.astype('float32')/255

# 独热编码
labels_train = keras.utils.to_categorical(labels_train,num_of_classes)
labels_test =keras.utils.to_categorical(labels_test,num_of_classes)

# 建立CNN模型
model = Sequential()
model.add(Conv2D(32, kernel_size=(3,3), activation='relu',input_shape=input_shape))
print("POST CONV2D: ",model.output_shape)
model.add(MaxPooling2D(pool_size=(2,2)))
print("POST MaxPooling2D: ", model.output_shape)
model.add(Dropout(0.25))
print("POST Gropout: ", model.output_shape)
model.add(Flatten())
print("POST Flatten: ", model.output_shape)
model.add(Dense(128, activation='relu'))
print("POST Dense: ", model.output_shape)
model.add(Dense(128, activation='relu'))
print("POST Dense1: ", model.output_shape)
model.add(Dense(num_of_classes, activation='softmax'))
print("POST Dense2: ", model.output_shape)

model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.Adadelta(),
              metrics=['accuracy'])

history = model.fit(features_train, labels_train,
          batch_size = batch_size,
          epochs = epochs,
          verbose = 1,
          validation_data = (features_test, labels_test))

score = model.evaluate(features_test, labels_test, verbose = 0)

# 保存模型
model.save('handwriteing_model.h5')

# 显示预测数据结果
print("\nTest score:", score[0])
print('Test accuracy:', score[1])
print(history.history.keys())

# 绘制准确率
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# 绘制损失
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# ('Test score:', 0.03451002207347774)
# ('Test accuracy:', 0.9877)
# ['acc', 'loss', 'val_acc', 'val_loss']
```


# RNN - 循环精神网络














